{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chicken-survival",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T04:54:27.473604Z",
     "iopub.status.busy": "2021-05-11T04:54:27.472800Z",
     "iopub.status.idle": "2021-05-11T04:56:13.939770Z",
     "shell.execute_reply": "2021-05-11T04:56:13.939164Z"
    },
    "papermill": {
     "duration": 106.499777,
     "end_time": "2021-05-11T04:56:13.939981",
     "exception": false,
     "start_time": "2021-05-11T04:54:27.440204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pycocotools20/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0) (3.4.1)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0) (0.29.23)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\r\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (7.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\r\n",
      "Installing collected packages: pycocotools\r\n",
      "Successfully installed pycocotools-2.0\r\n",
      "Processing /kaggle/input/pytorchzoomaster/pytorch_zoo-master\r\n",
      "Building wheels for collected packages: pytorch-zoo\r\n",
      "  Building wheel for pytorch-zoo (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pytorch-zoo: filename=pytorch_zoo-0.0.0-py3-none-any.whl size=30139 sha256=85da6cf22fbe427dd6277b0da8336da6b605d10d61bffd5e9a6eb55829ba49c2\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/36/1d/4e2a0ae6a85f0d674d74d871538c18856f7918f67b3dd35b13\r\n",
      "Successfully built pytorch-zoo\r\n",
      "Installing collected packages: pytorch-zoo\r\n",
      "Successfully installed pytorch-zoo-0.0.0\r\n",
      "Processing /kaggle/input/hpacellsegmentationmaster/HPA-Cell-Segmentation-master\r\n",
      "Building wheels for collected packages: hpacellseg\r\n",
      "  Building wheel for hpacellseg (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for hpacellseg: filename=hpacellseg-0.1.8-py3-none-any.whl size=14917 sha256=f2ec973e8606327d1acfdd375581b6696213a55e2ba51d05dcb8a071459e6f11\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/74/b4/e1de1965e419415f68a0098b1bf022570db6548a5ef09a79ed\r\n",
      "Successfully built hpacellseg\r\n",
      "Installing collected packages: hpacellseg\r\n",
      "Successfully installed hpacellseg-0.1.8\r\n",
      "Processing /kaggle/input/efficientnetpytorch\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.7.1) (1.7.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1) (3.7.4.3)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1) (1.19.5)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=20608 sha256=b1d0068e6b9aa98ff4e8a550aafc5be25341a730126b56f75fb017042fe2646e\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xsg9iiw2/wheels/ce/a6/b3/930f999d6bf4b6e4e6646ba9e17619777dd87458fffe1f5af8\r\n",
      "Successfully built efficientnet-pytorch\r\n",
      "Installing collected packages: efficientnet-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.7.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install '../input/pycocotools20/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl'\n",
    "!pip install '../input/pytorchzoomaster/pytorch_zoo-master'\n",
    "!pip install '../input/hpacellsegmentationmaster/HPA-Cell-Segmentation-master' --no-deps\n",
    "!pip install '../input/efficientnetpytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "right-arrangement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T04:56:13.991325Z",
     "iopub.status.busy": "2021-05-11T04:56:13.990578Z",
     "iopub.status.idle": "2021-05-11T04:56:17.428253Z",
     "shell.execute_reply": "2021-05-11T04:56:17.427613Z"
    },
    "papermill": {
     "duration": 3.465912,
     "end_time": "2021-05-11T04:56:17.428392",
     "exception": false,
     "start_time": "2021-05-11T04:56:13.962480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hpacellseg.cellsegmentator as cellsegmentator\n",
    "from hpacellseg.utils import label_cell, label_nuclei\n",
    "import numpy as np\n",
    "\n",
    "import multiprocessing\n",
    "import multiprocessing as mp\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import base64\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "import ast\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = 512\n",
    "CPU_COUNT = mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "higher-camping",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T04:56:17.499385Z",
     "iopub.status.busy": "2021-05-11T04:56:17.498473Z",
     "iopub.status.idle": "2021-05-11T04:56:38.135736Z",
     "shell.execute_reply": "2021-05-11T04:56:38.135232Z"
    },
    "papermill": {
     "duration": 20.684996,
     "end_time": "2021-05-11T04:56:38.135869",
     "exception": false,
     "start_time": "2021-05-11T04:56:17.450873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please compile abn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'pytorch_zoo.unet.DPNUnet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.upsampling.Upsample' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "test_dir = '../input/hpa-single-cell-image-classification/test/'\n",
    "\n",
    "!mkdir -p /kaggle/temp\n",
    "\n",
    "test_cells = '/kaggle/temp/test_cells/'\n",
    "!mkdir -p /kaggle/temp/test_cells\n",
    "\n",
    "test_nuclei = '/kaggle/temp/test_nuclei/'\n",
    "!mkdir -p /kaggle/temp/test_nuclei\n",
    "\n",
    "nuclei_512 = '/kaggle/temp/nuclei_512/'\n",
    "!mkdir -p /kaggle/temp/nuclei_512\n",
    "\n",
    "cells_512 = '/kaggle/temp/cells_512/'\n",
    "!mkdir -p /kaggle/temp/cells_512\n",
    "\n",
    "NUC_MODEL = \"../input/hpasegweights/dpn_unet_nuclei_v1.pth\"\n",
    "CELL_MODEL = \"../input/hpasegweights/dpn_unet_cell_3ch_v1.pth\"\n",
    "\n",
    "segmentator = cellsegmentator.CellSegmentator(\n",
    "    NUC_MODEL,\n",
    "    CELL_MODEL,\n",
    "    scale_factor=0.25,\n",
    "    device=\"cuda\",\n",
    "    padding=True,\n",
    "    multi_channel_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brief-quarter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T04:56:38.190384Z",
     "iopub.status.busy": "2021-05-11T04:56:38.189872Z",
     "iopub.status.idle": "2021-05-11T04:56:38.193254Z",
     "shell.execute_reply": "2021-05-11T04:56:38.193718Z"
    },
    "papermill": {
     "duration": 0.033607,
     "end_time": "2021-05-11T04:56:38.193878",
     "exception": false,
     "start_time": "2021-05-11T04:56:38.160271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_masks(cell_segmentation, nuc_segmentation, name):\n",
    "    nuclei_mask, cell_mask = label_cell(nuc_segmentation, cell_segmentation)\n",
    "    \n",
    "    ID = name.replace('_red.png','').split('/')[-1]\n",
    "    if cell_mask.max() < 256:\n",
    "        np.save(test_nuclei + ID + '.npy', nuclei_mask.astype(np.uint8))\n",
    "        np.save(test_cells + ID + '.npy', cell_mask.astype(np.uint8))\n",
    "    else:\n",
    "        np.save(test_nuclei + ID + '.npy', nuclei_mask)\n",
    "        np.save(test_cells + ID + '.npy', cell_mask)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wound-content",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T04:56:38.244623Z",
     "iopub.status.busy": "2021-05-11T04:56:38.244094Z",
     "iopub.status.idle": "2021-05-11T04:56:38.310924Z",
     "shell.execute_reply": "2021-05-11T04:56:38.310356Z"
    },
    "papermill": {
     "duration": 0.093577,
     "end_time": "2021-05-11T04:56:38.311056",
     "exception": false,
     "start_time": "2021-05-11T04:56:38.217479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mt = glob.glob(test_dir + '*_red.png')\n",
    "er = [f.replace('red', 'yellow') for f in mt]\n",
    "nu = [f.replace('red', 'blue') for f in mt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affected-madison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T04:56:38.364151Z",
     "iopub.status.busy": "2021-05-11T04:56:38.363332Z",
     "iopub.status.idle": "2021-05-11T05:53:22.392034Z",
     "shell.execute_reply": "2021-05-11T05:53:22.392893Z"
    },
    "papermill": {
     "duration": 3404.058824,
     "end_time": "2021-05-11T05:53:22.393140",
     "exception": false,
     "start_time": "2021-05-11T04:56:38.334316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 64 96 128 160 192 224 256 288 320 352 384 416 448 480 512 544 576 56.733264124393465\n"
     ]
    }
   ],
   "source": [
    "batch = 32\n",
    "pos = 0\n",
    "start_time = time.time()\n",
    "while pos < len(mt):\n",
    "\n",
    "    images = [mt[pos:pos+batch], er[pos:pos+batch], nu[pos:pos+batch]]\n",
    "    pos += batch\n",
    "\n",
    "    nuc_segmentations = segmentator.pred_nuclei(images[2])\n",
    "    cell_segmentations = segmentator.pred_cells(images)\n",
    "\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "    for i in range(len(cell_segmentations)):\n",
    "        name = images[0][i]\n",
    "        pool.apply_async(create_masks, args=(cell_segmentations[i], nuc_segmentations[i], name))\n",
    "        \n",
    "    pool.close()    \n",
    "    pool.join()\n",
    "    print(pos, end = ' ')\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time / 60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distributed-constraint",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T05:53:22.456172Z",
     "iopub.status.busy": "2021-05-11T05:53:22.455487Z",
     "iopub.status.idle": "2021-05-11T05:53:22.459101Z",
     "shell.execute_reply": "2021-05-11T05:53:22.458636Z"
    },
    "papermill": {
     "duration": 0.038041,
     "end_time": "2021-05-11T05:53:22.459208",
     "exception": false,
     "start_time": "2021-05-11T05:53:22.421167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_binary_mask(mask):\n",
    "\n",
    "    # check input mask --\n",
    "    if mask.dtype != np.bool:\n",
    "        raise ValueError(\"encode_binary_mask expects a binary mask, received dtype == %s\" % mask.dtype)\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(\"encode_binary_mask expects a 2d mask, received shape == %s\" % mask.shape)\n",
    "\n",
    "    # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return base64_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hungry-fundamentals",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T05:53:22.538239Z",
     "iopub.status.busy": "2021-05-11T05:53:22.527834Z",
     "iopub.status.idle": "2021-05-11T05:53:22.547610Z",
     "shell.execute_reply": "2021-05-11T05:53:22.547160Z"
    },
    "papermill": {
     "duration": 0.060591,
     "end_time": "2021-05-11T05:53:22.547718",
     "exception": false,
     "start_time": "2021-05-11T05:53:22.487127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_paddings(x_len, y_len):\n",
    "\n",
    "    pad_left, pad_right, pad_up, pad_down = 0, 0, 0, 0\n",
    "\n",
    "    if x_len > y_len:\n",
    "        pad_left = (x_len-y_len)//2\n",
    "        pad_right = x_len-y_len - pad_left\n",
    "    else:\n",
    "        pad_up = (y_len-x_len)//2\n",
    "        pad_down = y_len-x_len - pad_up\n",
    "\n",
    "    return pad_left, pad_right, pad_up, pad_down\n",
    "\n",
    "def load_this_image(image_path):\n",
    "    image = np.array(cv2.imread(image_path, cv2.IMREAD_UNCHANGED))\n",
    "    \n",
    "    if image.dtype == np.uint8:\n",
    "        image = image.astype(np.uint16)\n",
    "        image *= 257\n",
    "    \n",
    "    return image\n",
    "\n",
    "def get_cropped_channel_image_nuclei(image, top_left, bottom_right, mask, cell_id):\n",
    "    \n",
    "    image = image[top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1].copy()\n",
    "    image[(mask != 0) * (mask != cell_id)] = 0\n",
    "\n",
    "    pad_left, pad_right, pad_up, pad_down = get_paddings(image.shape[0], image.shape[1])\n",
    "    image = np.pad(image, [(pad_up, pad_down), (pad_left, pad_right)], mode='constant')\n",
    "\n",
    "    return image\n",
    "\n",
    "def get_cropped_channel_image_cells(image, top_left, bottom_right, mask, cell_id):\n",
    "    \n",
    "    image = image[top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1].copy()\n",
    "    image[mask != cell_id] = 0\n",
    "\n",
    "    pad_left, pad_right, pad_up, pad_down = get_paddings(image.shape[0], image.shape[1])\n",
    "    image = np.pad(image, [(pad_up, pad_down), (pad_left, pad_right)], mode='constant')\n",
    "\n",
    "    return image\n",
    "\n",
    "def get_mask_info(mask):\n",
    "    true_points = np.argwhere(mask)\n",
    "    \n",
    "    if not true_points.any():\n",
    "        return np.array([0, 0]), np.array([0, 0])\n",
    "    \n",
    "    top_left = true_points.min(axis=0)\n",
    "    bottom_right = true_points.max(axis=0)\n",
    "\n",
    "    return top_left, bottom_right\n",
    "\n",
    "def solve_nuclei(name):\n",
    "    \n",
    "    mask_dir = test_nuclei\n",
    "    \n",
    "    ID = name.replace('_red.png','').split('/')[-1]\n",
    "    \n",
    "    cell_mask = np.load(mask_dir + ID + '.npy')\n",
    "    max_id = cell_mask.max()\n",
    "    \n",
    "    image_per_channel = {}\n",
    "\n",
    "    for channel in ['_red', '_blue', '_green']:\n",
    "\n",
    "        image_filename = ID + channel + '.png'\n",
    "        image = load_this_image(test_dir + image_filename)\n",
    "\n",
    "        image_per_channel[channel] = image\n",
    "    \n",
    "    for curr_id in range(1, max_id+1):\n",
    "        \n",
    "        cell_info = get_mask_info(cell_mask == curr_id)\n",
    "        \n",
    "        top_left, bottom_right = cell_info[0], cell_info[1]\n",
    "        \n",
    "        dim1 = bottom_right[0]+1 - top_left[0]\n",
    "        dim2 = bottom_right[1]+1 - top_left[1]\n",
    "\n",
    "        pad_left, pad_right, pad_up, pad_down = get_paddings(dim1, dim2)\n",
    "        \n",
    "        top_left[1] -= pad_left + 16\n",
    "        bottom_right[1] += pad_right + 16\n",
    "        top_left[0] -= pad_up + 16\n",
    "        bottom_right[0] += pad_down + 16\n",
    "\n",
    "        top_left[0] = max(0, top_left[0])\n",
    "        top_left[1] = max(0, top_left[1])\n",
    "        bottom_right[0] = min(cell_mask.shape[0], bottom_right[0])\n",
    "        bottom_right[1] = min(cell_mask.shape[1], bottom_right[1])\n",
    "        \n",
    "        for channel in ['_red', '_blue', '_green']:\n",
    "            save_path = nuclei_512 + ID + '_' + str(curr_id-1) + channel + '.png'\n",
    "        \n",
    "            big_image = image_per_channel[channel]\n",
    "            image = get_cropped_channel_image_nuclei(big_image, cell_info[0], cell_info[1], cell_mask[top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1], curr_id)\n",
    "            \n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "            cv2.imwrite(save_path, image)\n",
    "            \n",
    "    return\n",
    "\n",
    "def solve_cells(name):\n",
    "    \n",
    "    masks = []\n",
    "    \n",
    "    mask_dir = test_cells\n",
    "    \n",
    "    ID = name.replace('_red.png','').split('/')[-1]\n",
    "    \n",
    "    cell_mask = np.load(mask_dir + ID + '.npy')\n",
    "    max_id = cell_mask.max()\n",
    "    \n",
    "    h = cell_mask.shape[0]\n",
    "    w = cell_mask.shape[1]\n",
    "    \n",
    "    image_per_channel = {}\n",
    "\n",
    "    for channel in ['_red', '_blue', '_green', '_yellow']:\n",
    "\n",
    "        image_filename = ID + channel + '.png'\n",
    "        image = load_this_image(test_dir + image_filename)\n",
    "\n",
    "        image_per_channel[channel] = image\n",
    "    for curr_id in range(1, max_id+1):\n",
    "        \n",
    "        binary_mask = cell_mask == curr_id\n",
    "        \n",
    "        masks.append(str(encode_binary_mask(binary_mask.astype(np.bool)))[2:-1])\n",
    "        \n",
    "        cell_info = get_mask_info(binary_mask)\n",
    "        \n",
    "        top_left, bottom_right = cell_info[0], cell_info[1]\n",
    "        \n",
    "        for channel in ['_red', '_blue', '_green', '_yellow']:\n",
    "        \n",
    "            save_path = cells_512 + ID + '_' + str(curr_id-1) + channel + '.png'\n",
    "        \n",
    "            big_image = image_per_channel[channel]\n",
    "            \n",
    "            image = get_cropped_channel_image_cells(big_image, cell_info[0], cell_info[1], cell_mask[top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1], curr_id)\n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "            cv2.imwrite(save_path, image)\n",
    "            \n",
    "    return ID, masks, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "final-parcel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T05:53:22.610358Z",
     "iopub.status.busy": "2021-05-11T05:53:22.609863Z",
     "iopub.status.idle": "2021-05-11T06:04:25.239542Z",
     "shell.execute_reply": "2021-05-11T06:04:25.240250Z"
    },
    "papermill": {
     "duration": 662.664456,
     "end_time": "2021-05-11T06:04:25.240479",
     "exception": false,
     "start_time": "2021-05-11T05:53:22.576023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.042728678385417\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pool = mp.Pool(CPU_COUNT)\n",
    "cell_mask_infos = []\n",
    "\n",
    "for x in mt:\n",
    "    pool.apply_async(solve_cells, args=(x,), callback=cell_mask_infos.append)\n",
    "    \n",
    "pool.close()    \n",
    "pool.join()\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time / 60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excellent-trance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:04:25.305098Z",
     "iopub.status.busy": "2021-05-11T06:04:25.304371Z",
     "iopub.status.idle": "2021-05-11T06:04:25.307859Z",
     "shell.execute_reply": "2021-05-11T06:04:25.307444Z"
    },
    "papermill": {
     "duration": 0.036229,
     "end_time": "2021-05-11T06:04:25.307974",
     "exception": false,
     "start_time": "2021-05-11T06:04:25.271745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_encodings = {}\n",
    "mask_w_h = {}\n",
    "for mask_info in cell_mask_infos:\n",
    "    mask_encodings[mask_info[0]] = mask_info[1]\n",
    "    mask_w_h[mask_info[0]] = (mask_info[2], mask_info[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "registered-carbon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:04:25.385278Z",
     "iopub.status.busy": "2021-05-11T06:04:25.376385Z",
     "iopub.status.idle": "2021-05-11T06:04:25.387639Z",
     "shell.execute_reply": "2021-05-11T06:04:25.387203Z"
    },
    "papermill": {
     "duration": 0.051969,
     "end_time": "2021-05-11T06:04:25.387740",
     "exception": false,
     "start_time": "2021-05-11T06:04:25.335771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mask_bounding_box(mask):\n",
    "    true_points = np.argwhere(mask)\n",
    "    \n",
    "    if not true_points.any():\n",
    "        return np.array([0, 0]), np.array([0, 0])\n",
    "    \n",
    "    top_left = true_points.min(axis=0)\n",
    "    bottom_right = true_points.max(axis=0)\n",
    "\n",
    "    return top_left, bottom_right\n",
    "\n",
    "def get_cropped_mask(mask, cell_id):\n",
    "    top_left, bottom_right = get_mask_bounding_box((mask == cell_id))\n",
    "\n",
    "    mask = mask[top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1].copy()\n",
    "    mask[mask != cell_id] = 0\n",
    "    mask[mask != 0] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "def ratio_to_value_multiplier(ratio):\n",
    "    if ratio > 0.3:\n",
    "        return 1.0\n",
    "    \n",
    "    if ratio > 0.01:\n",
    "        return (ratio * 3.33) ** 0.1\n",
    "\n",
    "    return 0.001\n",
    "\n",
    "def no_nuclei_and_border_cleaner(nuclei_mask, cell_mask, red, blue, yellow, values):\n",
    "    for i in range(len(values)):\n",
    "        index = i+1\n",
    "\n",
    "        if blue[nuclei_mask == index].sum() == 0:\n",
    "            values[i] *= 0.01\n",
    "            continue\n",
    "    \n",
    "        single_nuclei_mask = get_cropped_mask(nuclei_mask, index)\n",
    "        \n",
    "        lr = single_nuclei_mask.shape[0]\n",
    "        ud = single_nuclei_mask.shape[1]\n",
    "\n",
    "        up = single_nuclei_mask[0].sum()\n",
    "        down = single_nuclei_mask[-1].sum()\n",
    "        left = single_nuclei_mask[:, -0].sum()\n",
    "        right = single_nuclei_mask[:, -1].sum()\n",
    "\n",
    "        ud_ratio = (ud - max(up, down)) / ud\n",
    "        lr_ratio = (lr - max(left, right)) / lr\n",
    "\n",
    "        values[i] *= ratio_to_value_multiplier(ud_ratio) * ratio_to_value_multiplier(lr_ratio)\n",
    "\n",
    "    return values\n",
    "\n",
    "def no_blue_yellow_red_cleaner(nuclei_mask, cell_mask, red, blue, yellow, values):\n",
    "\n",
    "    red_sums = []\n",
    "    blue_yellow_products = []\n",
    "    valid_candidates = 0\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        index = i+1\n",
    "\n",
    "        if values[i] <= 0.01:\n",
    "            red_sums.append(0)\n",
    "            blue_yellow_products.append(0)\n",
    "            continue\n",
    "        \n",
    "        valid_candidates += 1\n",
    "\n",
    "        red_sum = red[cell_mask == index].sum()\n",
    "        blue_sum = blue[cell_mask == index].sum()\n",
    "        yellow_sum = yellow[cell_mask == index].sum()\n",
    "\n",
    "        red_sums.append(red_sum)\n",
    "        blue_yellow_products.append(blue_sum * yellow_sum)\n",
    "    \n",
    "    red_minimum = sum(red_sums) / valid_candidates * 0.077\n",
    "    blue_yellow_products_minimum = sum(blue_yellow_products) / valid_candidates * 0.05\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        index = i+1\n",
    "\n",
    "        if values[i] <= 0.01:\n",
    "            continue\n",
    "        \n",
    "        if red_sums[i] < red_minimum or blue_yellow_products[i] < blue_yellow_products_minimum:\n",
    "            values[i] *= 0.001\n",
    "    \n",
    "    return values\n",
    "\n",
    "class DataCleaner():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cleaners = [no_nuclei_and_border_cleaner, no_blue_yellow_red_cleaner]\n",
    "\n",
    "    def load_image(self, image_path):\n",
    "        image = np.array(cv2.imread(image_path, cv2.IMREAD_UNCHANGED))\n",
    "\n",
    "        if image.dtype == np.uint8:\n",
    "            image = image.astype(np.uint16)\n",
    "            image *= 257\n",
    "        \n",
    "        image = image.astype(np.float32)\n",
    "        image /= 65535\n",
    "\n",
    "        return image\n",
    "\n",
    "    def clean(self, image_id):\n",
    "        nuclei_mask = np.load(test_nuclei + image_id + '.npy')\n",
    "        cell_mask = np.load(test_cells + image_id + '.npy')\n",
    "        image_path = '../input/hpa-single-cell-image-classification/test/' + image_id\n",
    "        red = self.load_image(image_path + '_red.png')\n",
    "        blue = self.load_image(image_path + '_blue.png')\n",
    "        yellow = self.load_image(image_path + '_yellow.png')\n",
    "\n",
    "        values = [1.0] * cell_mask.max()\n",
    "\n",
    "        for cleaner in self.cleaners:\n",
    "            values = cleaner(nuclei_mask, cell_mask, red, blue, yellow, values)\n",
    "        \n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ordinary-glucose",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:04:25.447845Z",
     "iopub.status.busy": "2021-05-11T06:04:25.447303Z",
     "iopub.status.idle": "2021-05-11T06:04:25.451131Z",
     "shell.execute_reply": "2021-05-11T06:04:25.450729Z"
    },
    "papermill": {
     "duration": 0.035223,
     "end_time": "2021-05-11T06:04:25.451233",
     "exception": false,
     "start_time": "2021-05-11T06:04:25.416010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solve_data_cleaner(x):\n",
    "    dc = DataCleaner()\n",
    "    v = dc.clean(x)\n",
    "    return x, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fantastic-expert",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:04:25.514682Z",
     "iopub.status.busy": "2021-05-11T06:04:25.513930Z",
     "iopub.status.idle": "2021-05-11T06:08:39.365156Z",
     "shell.execute_reply": "2021-05-11T06:08:39.365780Z"
    },
    "papermill": {
     "duration": 253.886713,
     "end_time": "2021-05-11T06:08:39.365964",
     "exception": false,
     "start_time": "2021-05-11T06:04:25.479251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.230285461743673\n"
     ]
    }
   ],
   "source": [
    "image_names = [x.rsplit('/',1)[1][:-8] for x in mt]\n",
    "image_values = []\n",
    "\n",
    "start_time = time.time()\n",
    "pool = mp.Pool(CPU_COUNT)\n",
    "    \n",
    "for x in image_names:\n",
    "    pool.apply_async(solve_data_cleaner, args=(x,), callback=image_values.append)\n",
    "\n",
    "pool.close()    \n",
    "pool.join()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time / 60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "welcome-influence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:08:39.436963Z",
     "iopub.status.busy": "2021-05-11T06:08:39.436285Z",
     "iopub.status.idle": "2021-05-11T06:08:39.439169Z",
     "shell.execute_reply": "2021-05-11T06:08:39.438763Z"
    },
    "papermill": {
     "duration": 0.042939,
     "end_time": "2021-05-11T06:08:39.439272",
     "exception": false,
     "start_time": "2021-05-11T06:08:39.396333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "border_and_garbage_value = {}\n",
    "for ID, vals in image_values:\n",
    "    \n",
    "    for i in range(len(vals)):\n",
    "        border_and_garbage_value[ID + '_' + str(i)] = vals[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "liable-malawi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:08:39.510625Z",
     "iopub.status.busy": "2021-05-11T06:08:39.509894Z",
     "iopub.status.idle": "2021-05-11T06:08:39.512532Z",
     "shell.execute_reply": "2021-05-11T06:08:39.512129Z"
    },
    "papermill": {
     "duration": 0.044524,
     "end_time": "2021-05-11T06:08:39.512635",
     "exception": false,
     "start_time": "2021-05-11T06:08:39.468111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageMetadata():\n",
    "    def __init__(self, image_name, data_directory):\n",
    "        self.image_name = image_name\n",
    "        self.image_path = data_directory + image_name\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.image_path + ' - ' + str(self.image_labels)\n",
    "    \n",
    "class HPACellDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image_metadata, channels_num=4):\n",
    "        self.image_metadata = image_metadata\n",
    "        self.transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "        if channels_num == 3:\n",
    "            self.channels = ['_red', '_green', '_blue']\n",
    "        elif channels_num == 4:\n",
    "            self.channels = ['_red', '_green', '_blue', '_yellow']\n",
    "        else:\n",
    "            raise Exception('unsupported channels')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_metadata)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image_metadata = self.image_metadata[index]\n",
    "\n",
    "        channels = []\n",
    "\n",
    "        for channel in self.channels:\n",
    "\n",
    "            image = cv2.imread(image_metadata.image_path + channel + '.png', cv2.IMREAD_UNCHANGED)\n",
    "            image = image.astype(np.float32) / 65535.0\n",
    "            channels.append(image)\n",
    "        \n",
    "        image = np.dstack(channels)\n",
    "\n",
    "        return self.transforms(image), index\n",
    "\n",
    "def generate_image_id_to_image_names_dictionary(data_directory):\n",
    "\n",
    "    image_id_to_image_names_dictionary = {}\n",
    "    \n",
    "    image_names = set(image.rsplit('_',1)[0] for image in os.listdir(data_directory))\n",
    "\n",
    "    for image_name in image_names:\n",
    "        image_id = image_name.rsplit('_', 1)[0]\n",
    "\n",
    "        image_id_list = image_id_to_image_names_dictionary.get(image_id, [])\n",
    "        image_id_list.append(image_name)\n",
    "        image_id_to_image_names_dictionary[image_id] = image_id_list\n",
    "\n",
    "    return image_id_to_image_names_dictionary\n",
    "\n",
    "def get_test_loader(test_dir, batch_size = 4, num_workers = CPU_COUNT, in_channels=4):\n",
    "    image_id_to_image_name = generate_image_id_to_image_names_dictionary(test_dir)\n",
    "\n",
    "    test_images = [row[0] for row in csv.reader(open('../input/hpa-single-cell-image-classification/sample_submission.csv', 'r')) if row[0] != 'ID']\n",
    "\n",
    "    test_metadata = []\n",
    "    cnt = 0\n",
    "\n",
    "    for test_image in test_images:\n",
    "        # TODO removed\n",
    "        #if not test_image in image_id_to_image_name:\n",
    "            #continue\n",
    "        for test_cell in image_id_to_image_name[test_image]:\n",
    "            test_metadata.append(ImageMetadata(test_cell, test_dir))\n",
    "                                 \n",
    "    dataset = HPACellDataset(test_metadata, in_channels)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "    \n",
    "    return test_loader, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "natural-cancellation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:08:39.574138Z",
     "iopub.status.busy": "2021-05-11T06:08:39.573413Z",
     "iopub.status.idle": "2021-05-11T06:08:39.645224Z",
     "shell.execute_reply": "2021-05-11T06:08:39.644805Z"
    },
    "papermill": {
     "duration": 0.103674,
     "end_time": "2021-05-11T06:08:39.645331",
     "exception": false,
     "start_time": "2021-05-11T06:08:39.541657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO fix batch size? put 8 for b0 on GPU\n",
    "test_loader, dataset = get_test_loader(cells_512,8,CPU_COUNT, in_channels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "impaired-mortality",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:08:39.708431Z",
     "iopub.status.busy": "2021-05-11T06:08:39.707730Z",
     "iopub.status.idle": "2021-05-11T06:08:39.710470Z",
     "shell.execute_reply": "2021-05-11T06:08:39.710023Z"
    },
    "papermill": {
     "duration": 0.036282,
     "end_time": "2021-05-11T06:08:39.710586",
     "exception": false,
     "start_time": "2021-05-11T06:08:39.674304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_solution_values(solution_values_list, solution_values_weights):\n",
    "    result_solution_values = SolutionValues()\n",
    "\n",
    "    for i in range(len(solution_values_list)):\n",
    "        solution_values = solution_values_list[i]\n",
    "        weight = solution_values_weights[i]\n",
    "\n",
    "        for ID, num, label in solution_values.values:\n",
    "            value = solution_values.get_value(ID, num, label) * weight\n",
    "            result_solution_values.add_value(ID, num, label, value)\n",
    "    \n",
    "    return result_solution_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rubber-papua",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:08:39.787953Z",
     "iopub.status.busy": "2021-05-11T06:08:39.787229Z",
     "iopub.status.idle": "2021-05-11T06:08:39.789998Z",
     "shell.execute_reply": "2021-05-11T06:08:39.789604Z"
    },
    "papermill": {
     "duration": 0.050297,
     "end_time": "2021-05-11T06:08:39.790099",
     "exception": false,
     "start_time": "2021-05-11T06:08:39.739802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SolutionValues():\n",
    "    def __init__(self):\n",
    "        self.values = {}\n",
    "    \n",
    "    def add_value(self, ID, num, label, value):\n",
    "        key = (ID, num, label)\n",
    "        self.values[key] = self.values.get(key, 0) + value\n",
    "    \n",
    "    def get_value(self, ID, num, label):\n",
    "        key = (ID, num, label)\n",
    "        return self.values[key]\n",
    "\n",
    "    def weight_cells_per_image(self, cell_weight, image_weight, border_and_garbage_value):\n",
    "        temp_values = {}\n",
    "\n",
    "        for ID, num, label in self.values:\n",
    "            if label in [11, 18] or border_and_garbage_value[ID + '_' + str(num)] != 1.0:\n",
    "                continue\n",
    "\n",
    "            key = (ID, label)\n",
    "            value = self.values[(ID, num, label)]\n",
    "\n",
    "            if not key in temp_values:\n",
    "                temp_values[key] = []\n",
    "\n",
    "            temp_values[key].append(value)\n",
    "\n",
    "        for ID, num, label in self.values:\n",
    "            key = (ID, label)\n",
    "            if label in [11, 18] or not key in temp_values:\n",
    "                continue\n",
    "\n",
    "            value = self.values[(ID, num, label)] * cell_weight\n",
    "            value += sum(temp_values[key]) / len(temp_values[key]) * image_weight\n",
    "\n",
    "            self.values[(ID, num, label)] = value\n",
    "\n",
    "    def calculate_negatives(self):\n",
    "        temp_values = {}\n",
    "\n",
    "        for ID, num, label in self.values:\n",
    "            key = (ID, num)\n",
    "            value = self.values[(ID, num, label)]\n",
    "\n",
    "            if not key in temp_values:\n",
    "                temp_values[key] = []\n",
    "            \n",
    "            temp_values[key].append(value)\n",
    "        \n",
    "        for ID, num in temp_values:\n",
    "            key = (ID, num)\n",
    "            values = temp_values[(ID, num)]\n",
    "            \n",
    "            self.values[(ID, num, 18)] = 1.0 - max(values)\n",
    "    \n",
    "    def weight_border_and_garbage_images(self, border_and_garbage_value):\n",
    "        for ID, num, label in self.values:\n",
    "            self.values[(ID, num, label)] = self.values[(ID, num, label)] * border_and_garbage_value[ID + '_' + str(num)]\n",
    "        \n",
    "    def get_values_per_image(self):\n",
    "        values_per_image = {}\n",
    "\n",
    "        for ID, num, label in self.values:\n",
    "            key = (ID, num)\n",
    "            value = self.values[(ID, num, label)]\n",
    "\n",
    "            if not key in values_per_image:\n",
    "                values_per_image[key] = []\n",
    "\n",
    "            values_per_image[key].append((label, value))  \n",
    "\n",
    "        return values_per_image\n",
    "    \n",
    "    def to_submission_file(self, sample_submission_path, submission_path):\n",
    "        results = {}\n",
    "\n",
    "        d = self.get_values_per_image()\n",
    "\n",
    "        for x in d:\n",
    "            s = []    \n",
    "            image_name = x[0] + '_' + str(x[1])\n",
    "\n",
    "            for y in d[x]:\n",
    "                s.append(' '.join([str(y[0]), str(y[1]), mask_encodings[x[0]][x[1]]]))\n",
    "            s = ' '.join(s)\n",
    "            \n",
    "            t = results.get(x[0], [])\n",
    "            t.append(s)\n",
    "            results[x[0]] = t\n",
    "\n",
    "        with open(sample_submission_path, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            \n",
    "            missed = 0\n",
    "\n",
    "            with open(submission_path, 'w') as subf:\n",
    "                for row in reader:\n",
    "                    if row[0] in results:\n",
    "                        tmp = ' '.join(results[row[0]])\n",
    "                        print(f'{row[0]},{row[1]},{row[2]},{tmp}', file=subf)\n",
    "                    else:\n",
    "                        #print('SUCCESS!')\n",
    "                        missed += 1\n",
    "                        print(','.join(row), file=subf)\n",
    "            \n",
    "            print(\"MISSED:\", missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fabulous-gibraltar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:08:39.855992Z",
     "iopub.status.busy": "2021-05-11T06:08:39.855290Z",
     "iopub.status.idle": "2021-05-11T06:08:39.858021Z",
     "shell.execute_reply": "2021-05-11T06:08:39.857547Z"
    },
    "papermill": {
     "duration": 0.0387,
     "end_time": "2021-05-11T06:08:39.858117",
     "exception": false,
     "start_time": "2021-05-11T06:08:39.819417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_efficient_net_b0(state_dict_path):\n",
    "    net = EfficientNet.from_name('efficientnet-b0', in_channels=4, num_classes=18, image_size=512)\n",
    "    net._fc = nn.Sequential(nn.Linear(1280, 18), nn.Sigmoid())\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net.load_state_dict(torch.load(state_dict_path))\n",
    "        net.to(device)\n",
    "    else:\n",
    "        net.load_state_dict(torch.load(state_dict_path ,map_location=device))\n",
    "\n",
    "    net.eval()\n",
    "    \n",
    "    return net\n",
    "\n",
    "def get_efficient_net_b4(state_dict_path):\n",
    "    net = EfficientNet.from_name('efficientnet-b4', in_channels=4, num_classes=18, image_size=512)\n",
    "    net._fc = nn.Sequential(nn.Linear(1792, 18), nn.Sigmoid())\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net.load_state_dict(torch.load(state_dict_path))\n",
    "        net.to(device)\n",
    "    else:\n",
    "        net.load_state_dict(torch.load(state_dict_path ,map_location=device))\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daily-excitement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:08:39.923361Z",
     "iopub.status.busy": "2021-05-11T06:08:39.922605Z",
     "iopub.status.idle": "2021-05-11T06:08:39.924793Z",
     "shell.execute_reply": "2021-05-11T06:08:39.925231Z"
    },
    "papermill": {
     "duration": 0.038092,
     "end_time": "2021-05-11T06:08:39.925344",
     "exception": false,
     "start_time": "2021-05-11T06:08:39.887252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_net(net, test_loader, dataset):\n",
    "    net.eval()\n",
    "\n",
    "    solution_values = SolutionValues()\n",
    "\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "\n",
    "        inputs, indices = data\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        for batch_index in range(len(indices)):\n",
    "            dataset_index = indices[batch_index].item()\n",
    "            metadata = dataset.image_metadata[dataset_index]\n",
    "\n",
    "            image_name = metadata.image_name\n",
    "            splitter = image_name.rsplit('_', 1)\n",
    "            ID, num = splitter[0], int(splitter[1])\n",
    "\n",
    "            for label in range(18):\n",
    "\n",
    "                value = outputs[batch_index][label].item()\n",
    "                solution_values.add_value(ID, num, label, value)\n",
    "    \n",
    "    return solution_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "further-chapter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:08:39.990476Z",
     "iopub.status.busy": "2021-05-11T06:08:39.989877Z",
     "iopub.status.idle": "2021-05-11T06:22:21.280384Z",
     "shell.execute_reply": "2021-05-11T06:22:21.279874Z"
    },
    "papermill": {
     "duration": 821.325892,
     "end_time": "2021-05-11T06:22:21.280547",
     "exception": false,
     "start_time": "2021-05-11T06:08:39.954655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#b0 RESIZE ensemble\n",
    "net = get_efficient_net_b0('../input/cropytorchmodels/b0-resize-epoch-12-finetuned.pt')\n",
    "solution_values1 = evaluate_net(net, test_loader, dataset)\n",
    "\n",
    "net = get_efficient_net_b0('../input/cropytorchmodels/b0-resize-epoch-13-finetuned.pt')\n",
    "solution_values2 = evaluate_net(net, test_loader, dataset)\n",
    "\n",
    "net = get_efficient_net_b0('../input/cropytorchmodels/b0-resize-epoch-14-finetuned.pt')\n",
    "solution_values3 = evaluate_net(net, test_loader, dataset)\n",
    "\n",
    "net = get_efficient_net_b0('../input/cropytorchmodels/b0-resize-epoch-15-finetuned.pt')\n",
    "solution_values4 = evaluate_net(net, test_loader, dataset)\n",
    "\n",
    "solution_values_resize_ensemble = merge_solution_values([solution_values1, solution_values2, solution_values3, solution_values4], [0.20, 0.30, 0.30, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "streaming-cross",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:22:21.348784Z",
     "iopub.status.busy": "2021-05-11T06:22:21.347942Z",
     "iopub.status.idle": "2021-05-11T06:29:16.109621Z",
     "shell.execute_reply": "2021-05-11T06:29:16.109025Z"
    },
    "papermill": {
     "duration": 414.796958,
     "end_time": "2021-05-11T06:29:16.109768",
     "exception": false,
     "start_time": "2021-05-11T06:22:21.312810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = get_efficient_net_b0('../input/cropytorchmodels/b0-resize-and-pad-epoch-12-finetuned.pt')\n",
    "solution_values1 = evaluate_net(net, test_loader, dataset)\n",
    "\n",
    "net = get_efficient_net_b0('../input/cropytorchmodels/b0-resize-and-pad-epoch-13-finetuned.pt')\n",
    "solution_values2 = evaluate_net(net, test_loader, dataset)\n",
    "\n",
    "solution_values_resize_and_pad_ensemble = merge_solution_values([solution_values1, solution_values2], [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "trained-indonesian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:29:16.177117Z",
     "iopub.status.busy": "2021-05-11T06:29:16.176292Z",
     "iopub.status.idle": "2021-05-11T06:32:41.455882Z",
     "shell.execute_reply": "2021-05-11T06:32:41.456994Z"
    },
    "papermill": {
     "duration": 205.315961,
     "end_time": "2021-05-11T06:32:41.457224",
     "exception": false,
     "start_time": "2021-05-11T06:29:16.141263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = get_efficient_net_b0('../input/cropytorchmodels/b0-old.pt')\n",
    "solution_values_old_b0 = evaluate_net(net, test_loader, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "secondary-brand",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:32:41.568779Z",
     "iopub.status.busy": "2021-05-11T06:32:41.568026Z",
     "iopub.status.idle": "2021-05-11T06:32:42.253298Z",
     "shell.execute_reply": "2021-05-11T06:32:42.253950Z"
    },
    "papermill": {
     "duration": 0.74514,
     "end_time": "2021-05-11T06:32:42.254128",
     "exception": false,
     "start_time": "2021-05-11T06:32:41.508988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "solution_values = merge_solution_values([solution_values_resize_ensemble, solution_values_resize_and_pad_ensemble, solution_values_old_b0], [0.40, 0.40, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "particular-queens",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:32:42.364195Z",
     "iopub.status.busy": "2021-05-11T06:32:42.354000Z",
     "iopub.status.idle": "2021-05-11T06:32:43.311366Z",
     "shell.execute_reply": "2021-05-11T06:32:43.310895Z"
    },
    "papermill": {
     "duration": 1.026283,
     "end_time": "2021-05-11T06:32:43.311494",
     "exception": false,
     "start_time": "2021-05-11T06:32:42.285211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "solution_values.calculate_negatives()\n",
    "solution_values.weight_border_and_garbage_images(border_and_garbage_value)\n",
    "solution_values.weight_cells_per_image(0.7, 0.3, border_and_garbage_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "married-raleigh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T06:32:43.418335Z",
     "iopub.status.busy": "2021-05-11T06:32:43.413355Z",
     "iopub.status.idle": "2021-05-11T06:32:44.110877Z",
     "shell.execute_reply": "2021-05-11T06:32:44.110069Z"
    },
    "papermill": {
     "duration": 0.768978,
     "end_time": "2021-05-11T06:32:44.111057",
     "exception": false,
     "start_time": "2021-05-11T06:32:43.342079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSED: 1\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SUBMISSION = '../input/hpa-single-cell-image-classification/sample_submission.csv'\n",
    "SUBMISSION = '../working/submission.csv'\n",
    "solution_values.to_submission_file(SAMPLE_SUBMISSION, SUBMISSION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5907.408657,
   "end_time": "2021-05-11T06:32:47.738211",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-11T04:54:20.329554",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
